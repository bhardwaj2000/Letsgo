<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Latest &#8211; letsgo</title>
	<atom:link href="https://bhardwaj2000.github.io/Letsgo/category/technology/latest/feed/" rel="self" type="application/rss+xml" />
	<link>http://bhardwaj2000.github.io/Letsgo/</link>
	<description>Just another WordPress site</description>
	<lastBuildDate>Mon, 22 Jun 2020 14:14:32 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.4.2</generator>

<image>
	<url>https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/cropped-Letsgo-2-32x32.png</url>
	<title>Latest &#8211; letsgo</title>
	<link>http://bhardwaj2000.github.io/Letsgo/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Carbon nanotube field-effect transistor</title>
		<link>https://bhardwaj2000.github.io/Letsgo/2020/06/22/carbon-nanotube-field-effect-transistor/</link>
					<comments>https://bhardwaj2000.github.io/Letsgo/2020/06/22/carbon-nanotube-field-effect-transistor/#respond</comments>
		
		<dc:creator><![CDATA[admin]]></dc:creator>
		<pubDate>Mon, 22 Jun 2020 14:14:29 +0000</pubDate>
				<category><![CDATA[Latest]]></category>
		<category><![CDATA[Technology]]></category>
		<guid isPermaLink="false">https://bhardwaj2000.github.io/Letsgo/?p=47</guid>

					<description><![CDATA[<img width="259" height="194" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index7.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" />A carbon nanotube field-effect transistor (CNTFET) refers to a field-effect transistor that utilizes a single carbon nanotube or an array of carbon nanotubes as the channel material instead of bulk silicon in the traditional MOSFET structure. First demonstrated in 1998, there have been major developments in CNTFETs since.]]></description>
										<content:encoded><![CDATA[<img width="259" height="194" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index7.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" />
<p>A <strong>carbon nanotube field-effect transistor (CNTFET)</strong> refers to a <a href="https://en.wikipedia.org/wiki/Field-effect_transistor">field-effect transistor</a> that utilizes a single <a href="https://en.wikipedia.org/wiki/Carbon_nanotube">carbon nanotube</a> or an array of carbon nanotubes as the channel material instead of bulk <a href="https://en.wikipedia.org/wiki/Silicon">silicon</a> in the traditional <a href="https://en.wikipedia.org/wiki/MOSFET">MOSFET</a> structure. First demonstrated in 1998, there have been major developments in CNTFETs since.</p>



<p>Wrap-around gate CNTFETs, also known as gate-all-around CNTFETs were developed in 2008,<sup><a href="https://en.wikipedia.org/wiki/Carbon_nanotube_field-effect_transistor#cite_note-20">[20]</a></sup> and are a further improvement upon the top-gate device geometry. In this device, instead of gating just the part of the CNT that is closer to the metal gate contact, the entire circumference of the nanotube is gated. This should ideally improve the electrical performance of the CNTFET, reducing leakage current and improving the device on/off ratio.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://bhardwaj2000.github.io/Letsgo/2020/06/22/carbon-nanotube-field-effect-transistor/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Electronic nose</title>
		<link>https://bhardwaj2000.github.io/Letsgo/2020/06/22/electronic-nose/</link>
					<comments>https://bhardwaj2000.github.io/Letsgo/2020/06/22/electronic-nose/#respond</comments>
		
		<dc:creator><![CDATA[admin]]></dc:creator>
		<pubDate>Mon, 22 Jun 2020 14:08:17 +0000</pubDate>
				<category><![CDATA[Latest]]></category>
		<category><![CDATA[Technology]]></category>
		<guid isPermaLink="false">https://bhardwaj2000.github.io/Letsgo/?p=44</guid>

					<description><![CDATA[<img width="220" height="220" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/220px-An_Electronic_Nose_Estimates_Odor_Pleasantness.png" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" srcset="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/220px-An_Electronic_Nose_Estimates_Odor_Pleasantness.png 220w, https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/220px-An_Electronic_Nose_Estimates_Odor_Pleasantness-150x150.png 150w" sizes="(max-width: 220px) 100vw, 220px" />An electronic nose is a device intended to detect odors or flavors.]]></description>
										<content:encoded><![CDATA[<img width="220" height="220" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/220px-An_Electronic_Nose_Estimates_Odor_Pleasantness.png" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" srcset="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/220px-An_Electronic_Nose_Estimates_Odor_Pleasantness.png 220w, https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/220px-An_Electronic_Nose_Estimates_Odor_Pleasantness-150x150.png 150w" sizes="(max-width: 220px) 100vw, 220px" />
<p>An <strong>electronic nose</strong> is a device intended to detect <a href="https://en.wikipedia.org/wiki/Odor">odors</a> or <a href="https://en.wikipedia.org/wiki/Flavor">flavors</a>.</p>



<p>Over the last decades, &#8220;electronic sensing&#8221; or &#8220;e-sensing&#8221; technologies have undergone important developments from a technical and commercial point of view. The expression &#8220;electronic sensing&#8221; refers to the capability of reproducing human senses using sensor arrays and <a href="https://en.wikipedia.org/wiki/Pattern_recognition">pattern recognition</a> systems. Since 1982,<sup><a href="https://en.wikipedia.org/wiki/Electronic_nose#cite_note-2">[2]</a></sup> research has been conducted to develop technologies, commonly referred to as electronic noses, that could detect and recognize odors and flavors. The stages of the recognition process are similar to human <a href="https://en.wikipedia.org/wiki/Olfaction">olfaction</a> and are performed for identification, comparison, <a href="https://en.wikipedia.org/wiki/Quantification_(science)">quantification</a> and other applications, including <a href="https://en.wikipedia.org/wiki/Computer_data_storage">data storage</a> and retrieval. However, <a href="https://en.wikipedia.org/wiki/Hedonic">hedonic</a> evaluation is a specificity of the human nose given that it is related to subjective opinions. These devices have undergone much development and are now used to fulfill industrial needs.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://bhardwaj2000.github.io/Letsgo/2020/06/22/electronic-nose/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Digital scent technology</title>
		<link>https://bhardwaj2000.github.io/Letsgo/2020/06/22/digital-scent-technology/</link>
					<comments>https://bhardwaj2000.github.io/Letsgo/2020/06/22/digital-scent-technology/#respond</comments>
		
		<dc:creator><![CDATA[admin]]></dc:creator>
		<pubDate>Mon, 22 Jun 2020 14:06:38 +0000</pubDate>
				<category><![CDATA[Latest]]></category>
		<category><![CDATA[Technology]]></category>
		<guid isPermaLink="false">https://bhardwaj2000.github.io/Letsgo/?p=41</guid>

					<description><![CDATA[<img width="259" height="194" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index56.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" />Digital scent technology (or olfactory technology) is the engineering discipline dealing with olfactory representation. ]]></description>
										<content:encoded><![CDATA[<img width="259" height="194" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index56.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" />
<p><strong>Digital scent technology</strong> (or <strong>olfactory technology</strong>) is the engineering discipline dealing with <a href="https://en.wikipedia.org/wiki/Olfaction">olfactory</a> representation. It is a technology to sense, transmit and receive <a href="https://en.wikipedia.org/wiki/Odor">scent</a>-enabled digital media (such as web pages, <a href="https://en.wikipedia.org/wiki/Video_game">video games</a>, <a href="https://en.wikipedia.org/wiki/Movie">movies</a> and <a href="https://en.wikipedia.org/wiki/Music">music</a>). This sensing part of this technology works by using <a href="https://en.wikipedia.org/wiki/Olfactometer">olfactometers</a> and <a href="https://en.wikipedia.org/wiki/Electronic_nose">electronic noses</a>.</p>



<p>During ThinkNext 2010, the Israeli company Scentcom featured a demo of its scent-generating device.<sup><a href="https://en.wikipedia.org/wiki/Digital_scent_technology#cite_note-12">[12]</a></sup></p>



<p>In June 2011, a press release from the <a href="https://en.wikipedia.org/wiki/University_of_California,_San_Diego">University of California, San Diego</a> <a href="https://en.wikipedia.org/wiki/Jacobs_School_of_Engineering">Jacobs School of Engineering</a><sup><a href="https://en.wikipedia.org/wiki/Digital_scent_technology#cite_note-13">[13]</a></sup> announced a paper published in <a href="https://en.wikipedia.org/wiki/Angewandte_Chemie">Angewandte Chemie</a><sup><a href="https://en.wikipedia.org/wiki/Digital_scent_technology#cite_note-14">[14]</a></sup> describing an optimization and miniaturization of a component that can select and release scents from 10,000 odors, that is intended to be part of a Digital scent solution for TVs and phones.</p>



<p>In October 2012, Aromajoin, a Japanese company, released a small-sized product named Aroma Shooter which contains 6 different solid-type scents.<sup><a href="https://en.wikipedia.org/wiki/Digital_scent_technology#cite_note-15">[15]</a></sup></p>



<p>In March 2013, a group of Japanese researchers unveiled a prototype invention they dubbed a &#8220;<a href="https://en.wikipedia.org/wiki/Smelling_screen">smelling screen</a>&#8220;. The device combines a digital display with four small fans that direct an emitted odor to a specific spot on the screen. The fans operate at a very low speed, making it difficult for the user to perceive airflow; instead they perceive the smell as coming directly out of the screen and object displayed at that location.<sup><a href="https://en.wikipedia.org/wiki/Digital_scent_technology#cite_note-16">[16]</a></sup></p>



<p>In July 2013, Raul Porcar (Spain), engineer and inventor developed and patented <a href="https://www.olorama.com">Olorama Technology</a>, a wireless system with the aim to incorporate scents into movies, Virtual Reality, and all kind of audiovisual experiences.:<sup><a href="https://en.wikipedia.org/wiki/Digital_scent_technology#cite_note-17">[17]</a></sup></p>



<p>In December 2013 Amos Porat inventor and CTO Of scent2you Israel Company has built several prototypes that can control scents.<sup><a href="https://en.wikipedia.org/wiki/Digital_scent_technology#cite_note-18">[18]</a></sup></p>



<p>At GDC 2015, FeelReal unveiled its odor generator <a href="https://en.wikipedia.org/wiki/Virtual_Reality">VR</a> peripheral.<sup><a href="https://en.wikipedia.org/wiki/Digital_scent_technology#cite_note-19">[19]</a></sup></p>



<p>In 2016 Surina Hariri, Nur Ain Mustafa, Kasun Karunanayaka and Adrian David Cheok from Imagineering Institute, Iskandar Puteri, Malaysia experimented with Electrical stimulation of olfactory receptors.<sup><a href="https://en.wikipedia.org/wiki/Digital_scent_technology#cite_note-20">[20]</a></sup></p>



<p>At CEATEC 2016, Aromajoin unveiled the first wearable scent device, Aroma Shooter Mini, which can be connected and controlled from PCs and smartphones. Besides, the company also introduced a demo scent-enabled chatting app named AromaMessage in the event.<sup><a href="https://en.wikipedia.org/wiki/Digital_scent_technology#cite_note-21">[21]</a></sup> <sup><a href="https://en.wikipedia.org/wiki/Digital_scent_technology#cite_note-22">[22]</a></sup></p>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>https://bhardwaj2000.github.io/Letsgo/2020/06/22/digital-scent-technology/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>NASA Set to Demonstrate X-ray Communications in Space</title>
		<link>https://bhardwaj2000.github.io/Letsgo/2020/06/22/nasa-set-to-demonstrate-x-ray-communications-in-space/</link>
					<comments>https://bhardwaj2000.github.io/Letsgo/2020/06/22/nasa-set-to-demonstrate-x-ray-communications-in-space/#respond</comments>
		
		<dc:creator><![CDATA[admin]]></dc:creator>
		<pubDate>Mon, 22 Jun 2020 14:02:47 +0000</pubDate>
				<category><![CDATA[Latest]]></category>
		<category><![CDATA[Technology]]></category>
		<guid isPermaLink="false">https://bhardwaj2000.github.io/Letsgo/?p=38</guid>

					<description><![CDATA[<img width="237" height="213" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index5.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" />A new experimental type of deep space communications technology is scheduled to be demonstrated on the International Space Station this spring.]]></description>
										<content:encoded><![CDATA[<img width="237" height="213" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index5.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" />
<p>A new experimental type of deep space communications technology is scheduled to be demonstrated on the International Space Station this spring.</p>



<p>Currently, NASA relies on radio waves to send information between spacecraft and Earth. Emerging <a href="https://www.nasa.gov/sites/default/files/atoms/files/lcrd_factsheet_oct2018.pdf">laser communications</a> technology offers higher data rates that let spacecraft transmit more data at a time. This demonstration involves X-ray communications, or XCOM, which offers even more advantages.</p>



<p>X-rays have much shorter wavelengths than both infrared and radio. This means that, in principle, XCOM can send more data for the same amount of transmission power. The X-rays can broadcast in tighter beams, thus using less energy when communicating over vast distances.</p>



<p>If successful, the experiment could increase interest in the communications technology, which could permit more efficient gigabits-per-second data rates for deep space missions. Gigabits per second is a data transfer rate equivalent to one billion bits, or simple binary units, per second. These extremely high-speed rates of data transfer are not currently common, but new research projects have pushed computing capability toward this range for some technologies.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://bhardwaj2000.github.io/Letsgo/2020/06/22/nasa-set-to-demonstrate-x-ray-communications-in-space/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Virtual Reality</title>
		<link>https://bhardwaj2000.github.io/Letsgo/2020/06/22/virtual-reality/</link>
					<comments>https://bhardwaj2000.github.io/Letsgo/2020/06/22/virtual-reality/#respond</comments>
		
		<dc:creator><![CDATA[admin]]></dc:creator>
		<pubDate>Mon, 22 Jun 2020 13:59:53 +0000</pubDate>
				<category><![CDATA[Latest]]></category>
		<category><![CDATA[Technology]]></category>
		<guid isPermaLink="false">https://bhardwaj2000.github.io/Letsgo/?p=35</guid>

					<description><![CDATA[<img width="300" height="168" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index4.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" />Virtual reality (VR) is a simulated experience that can be similar to or completely different from the real world.]]></description>
										<content:encoded><![CDATA[<img width="300" height="168" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index4.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" />
<p><strong>Virtual reality</strong> (<strong>VR</strong>) is a <a href="https://en.wikipedia.org/wiki/Simulation">simulated</a> experience that can be similar to or completely different from the real world. <a href="https://en.wikipedia.org/wiki/Applications_of_virtual_reality">Applications of virtual reality</a> can include entertainment (i.e. <a href="https://en.wikipedia.org/wiki/Video_game">video games</a>) and educational purposes (i.e. medical or military training). Other, distinct types of VR style technology include <a href="https://en.wikipedia.org/wiki/Augmented_reality">augmented reality</a> and <a href="https://en.wikipedia.org/wiki/Mixed_reality">mixed reality</a>.</p>



<p>Currently standard virtual reality systems use either <a href="https://en.wikipedia.org/wiki/Virtual_reality_headset">virtual reality headsets</a> or multi-projected environments to generate realistic images, sounds and other sensations that simulate a user&#8217;s physical presence in a virtual environment. A person using virtual reality equipment is able to look around the artificial world, move around in it, and interact with virtual features or items. The effect is commonly created by VR headsets consisting of a <a href="https://en.wikipedia.org/wiki/Head-mounted_display">head-mounted display</a> with a small screen in front of the eyes, but can also be created through specially designed rooms with multiple large screens. Virtual reality typically incorporates <a href="https://en.wikipedia.org/wiki/Auditory_feedback">auditory</a> and <a href="https://en.wikipedia.org/wiki/Video_feedback">video feedback</a>, but may also allow other types of sensory and force feedback through <a href="https://en.wikipedia.org/wiki/Haptic_technology">haptic technology</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://bhardwaj2000.github.io/Letsgo/2020/06/22/virtual-reality/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Subvocal recognition</title>
		<link>https://bhardwaj2000.github.io/Letsgo/2020/06/22/subvocal-recognition/</link>
					<comments>https://bhardwaj2000.github.io/Letsgo/2020/06/22/subvocal-recognition/#respond</comments>
		
		<dc:creator><![CDATA[admin]]></dc:creator>
		<pubDate>Mon, 22 Jun 2020 13:56:59 +0000</pubDate>
				<category><![CDATA[Latest]]></category>
		<category><![CDATA[Technology]]></category>
		<guid isPermaLink="false">https://bhardwaj2000.github.io/Letsgo/?p=32</guid>

					<description><![CDATA[<img width="256" height="197" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index3.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" />Subvocal recognition (SVR) is the process of taking subvocalization and converting the detected results to a digital output, aural or text-based.]]></description>
										<content:encoded><![CDATA[<img width="256" height="197" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index3.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" />
<p><strong>Subvocal recognition</strong> (SVR) is the process of taking <a href="https://en.wikipedia.org/wiki/Subvocalization">subvocalization</a> and converting the detected results to a digital output, aural or text-based.</p>



<p>A set of <a href="https://en.wikipedia.org/wiki/Electrodes">electrodes</a> are attached to the skin of the <a href="https://en.wikipedia.org/wiki/Throat">throat</a> and, without opening the <a href="https://en.wikipedia.org/wiki/Mouth">mouth</a> or uttering a sound, the words are recognized by a computer.</p>



<p>Subvocal speech recognition deals with <a href="https://en.wikipedia.org/wiki/Electromyogram">electromyograms</a> that are different for each speaker. Therefore, consistency can be thrown off just by the positioning of an <a href="https://en.wikipedia.org/wiki/Electrode">electrode</a>. To improve accuracy, researchers in this field are relying on statistical models that get better at <a href="https://en.wikipedia.org/wiki/Pattern">pattern</a>-matching the more times a subject &#8220;speaks&#8221; through the electrodes, but even then there are lapses. At <a href="https://en.wikipedia.org/wiki/Carnegie_Mellon_University">Carnegie Mellon University</a>, researchers found that the same &#8220;speaker&#8221; with accuracy rates of 94% one day can see that rate drop to 48% a day later; between two different speakers it drops even more.<sup>[<em><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed">citation needed</a></em>]</sup></p>



<p>Relevant applications for this technology where audible speech is impossible: for <a href="https://en.wikipedia.org/wiki/Astronauts">astronauts</a>, underwater <a href="https://en.wikipedia.org/wiki/Navy_Seals">Navy Seals</a>, fighter pilots and emergency workers charging into loud, harsh environments. At <a href="https://en.wikipedia.org/wiki/Worcester_Polytechnic_Institute">Worcester Polytechnic Institute</a> in Massachusetts, research is underway to use subvocal information as a control source for computer music instruments.<sup>[<em><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed">citation needed</a></em>]</sup></p>
]]></content:encoded>
					
					<wfw:commentRss>https://bhardwaj2000.github.io/Letsgo/2020/06/22/subvocal-recognition/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Speech recognition</title>
		<link>https://bhardwaj2000.github.io/Letsgo/2020/06/22/speech-recognition/</link>
					<comments>https://bhardwaj2000.github.io/Letsgo/2020/06/22/speech-recognition/#respond</comments>
		
		<dc:creator><![CDATA[admin]]></dc:creator>
		<pubDate>Mon, 22 Jun 2020 13:53:50 +0000</pubDate>
				<category><![CDATA[Latest]]></category>
		<category><![CDATA[Technology]]></category>
		<guid isPermaLink="false">https://bhardwaj2000.github.io/Letsgo/?p=29</guid>

					<description><![CDATA[<img width="304" height="166" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index1.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" srcset="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index1.jpg 304w, https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index1-300x164.jpg 300w" sizes="(max-width: 304px) 100vw, 304px" />Speech recognition is the ability of a machine or program to identify words and phrases in spoken language and convert them to a machine-readable format. ]]></description>
										<content:encoded><![CDATA[<img width="304" height="166" src="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index1.jpg" class="attachment-large size-large wp-post-image" alt="" style="float:left; margin:0 15px 15px 0;" srcset="https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index1.jpg 304w, https://bhardwaj2000.github.io/Letsgo/wp-content/uploads/2020/06/index1-300x164.jpg 300w" sizes="(max-width: 304px) 100vw, 304px" />
<p>Speech recognition is the ability of a machine or <a href="https://searchsoftwarequality.techtarget.com/definition/program">program</a> to identify words and phrases in spoken language and convert them to a machine-readable format. Rudimentary speech recognition software has a limited vocabulary of words and phrases, and it may only identify these if they are spoken very clearly. More sophisticated <a href="https://searchapparchitecture.techtarget.com/definition/software">software</a> has the ability to accept natural speech.</p>



<h3>How it works</h3>



<p>Speech recognition works using algorithms through acoustic and language modeling. Acoustic modeling represents the relationship between linguistic units of speech and audio signals; language modeling matches sounds with word sequences to help distinguish between words that sound similar.</p>



<p>Often, hidden Markov models are used as well to recognize temporal patterns in speech to improve accuracy within the system.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://bhardwaj2000.github.io/Letsgo/2020/06/22/speech-recognition/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
